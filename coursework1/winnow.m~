%Part 2 excercise 4 a, winnow

clear

%max_m = 50;
max_n = 50;
m = 1;

for n = 1:max_n
    %initial
    sample_complexity = 1;
    error_ratio = 1;
    w = ones(n,1);
    T = 100*n;
    %perceptron
    while(error_ratio > 0.1)
        m = m + 1;
        error = 1;
        for i = 1 : m
            x = sign(-0.5 + rand(m,n));
            for k = 1 : m
                for l = 1 : n
                    if(x(k,l) == -1)
                        x(k,l) = 0;
                    end
                end
            end
            y = x(:,1);
            for t = 1 : T
                y_train(i,:) = sign(x(i,:)*w);
	            if(y_train(i,:) ~= y(i,:))
                    if (y(i,:) == 1)
                    w = 2*w;
                    else
                    w = 0;
                end
            end
        end
        for i = 1 : m
        	y_train(i,:) = sign(x(i,:)*w);
            if(y_train(i,:) ~= y(i,:))
                error = error + 1;
            end
        end
        error_ratio = error/m;
        generalisation_error_rate = error_ratio + (log(1/0.01)/(2*m))^(0.5);
        %sample_complexity = 2^(-n) * error;
    end
    m_plot(n) = m;
end

figure; plot(1:max_n, m_plot);
title('perceptron')
xlabel('n')
ylabel('m')
